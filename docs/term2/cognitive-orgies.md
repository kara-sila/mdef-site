# The Altered Present Metronom
Exploring digital presence as a collective condition, using AI to reconfigure how bodies relate to space and to each other.
[--> Go to the Hackster.io documentation](https://www.hackster.io/544089/altered-present-metronom-e3a06a)

### Background
Armin and I worked on this project together. We mapped our areas of interests and came up with three main concepts; 
* dance, movement, motion
* alternative narratives
* driving human behavior

<img width="448" height="499" alt="Screenshot 2026-02-14 at 09 56 13" src="https://github.com/user-attachments/assets/51b636ef-de98-4148-8ef2-f261cab07d5f" />

My research is on dance and movement in public spaces, and how it can create an alternative narrative for public spaces; while his is on how we extend our body/brain with technology, and with that how technology can drive our behavior. With these in mind we knew we wanted to focus on the intersection of movement and technology and came up with a shared research question;
**Can an alternative digital presense help people become more connected to their physical environment by movement?**

We had three ideas to work on. The first one was to use mapping, projecting interactive abstract surfaces; however, this required a portable projector which we didn't have (Referance: Refik Anadol). The second idea was to create an alternative visual of the space with the use of glasses, and this in the end is a highly individual experience (Referance: Google Lens). Although we were not pushing for a movement of multiple people, we wanted to create a space where this is possible. The final decision was to create a metronom-like device where we drive the movement with a phone and the metronom sound (which is kind of a ritual). 

### The Prototype
We worked on a metronom looking prototype to create a feeling of the metronom idea, where dancers, musicians and many professionals use for cues and to understand when to move. This was the core idea of our 3D shape, and we decided that the mechanism of a metronom was not needed but the visual representation was the important point. We tried early cardboard mock-ups, 3D prints with different materials.
<img width="2114" height="1089" alt="Frame 27" src="https://github.com/user-attachments/assets/53a7d4ea-820e-4603-b87d-e57c3729e349" />

Our final prototype is a 3D printed metronom-like device which creates an interactive experience through the mobile camera and projection. The captured environment with the mobile camera is altered with a real-time generative AI image modification. 
![IMG_4902](https://github.com/user-attachments/assets/235f3323-a73e-42fd-b5ad-9a23e0394870)

### Cognitive Traces

The first cognitive trace was mapping our interests and coming up with the main topics to shape our project. I think what we're working on personally does overlap on some areas however his focus is on technology where mine doesn't include any high technology or AI. While starting the cognitive orgies, I wanted to use that week to open up my horizon and the scope of my project. One of the things I was considering implementing into my project is using the data of people and integrating it with AI mediation. While discussing on the share research question I believe we found an equal overlap where it seems like it was further from my topic, it helped me to test my idea on the AI mediation.

After finding the middle ground we discussed different options and referances for our project. Mostly what we were discussing didn't have a physical outcome. This is something I struggle a lot also in my personal project; turn movement into something solid. Our final decision was to create a metronom-like object for the phone.

One of the most important aspect of our project was the visual. We made a lot of changes, tried different concepts and iterated on the mechanism. We used TouchDesigner, Armin was the TD prof of our team, to change the environment into something forest-like, add metronom sound, and show humans as traces where they can regocnize themselves but not really see themselves fully.

### Moral Traces

The ethical aspect of our project was potentially the one we discussed the most. We wanted to create an alternative narrative of the environment to drive the movement and eventually their interaction with the space. However, this opened many questions;
* What other possible outcomes might happen with creating an alternative digital environment?
* Is it possible what we create might detach people from their environments more rather then creating a connection?
* What kind of outcomes using people's personal phones and their data (camera view) might create?
* Is it ok to project the environment and capture people without their consent?

We decided on using phones where people have to put their own device which would mean they give their consent to interact. However we could have designed a better experience to be more open on how what data is used, that it's not shared or saved. This was one of the reasons why we captured the environment but only showed human bodies as traces.

We iterated a lot on the TouchDesigner visual to represent our idea better. This required a lot of alignment and communication to make sure that we were on the same page and still pursuing our shared research question.

### Technical Traces

When we discussed on capturing the environment and changing it with AI to generate and alternative visual we were thinking about only using TouchDesigner. However at the end we had to use other apps, and technologies to make that happen. We made it work; however, in the real usage scenario and for testing this creates more complications.

Early on the ideation, after deciding on the 3D shape, we wanted to use wood to represent the metronom idea better. However, after designing the product on Rhino, we decided that the 3D printing was a more suitable technology. To save time and use less printers, we collaborated with another team and printed together. We printed our prototype with a transparent material which created a lot of problems. Although the second test print was good, we observed some problems on the object and stopped printing. After trying different temperatures we did fix the problem. During the second day we dropped the prototype and broke it :) I believe this was also because of the transparent material. Therefore for our last prototype we did use another material.


## Main Challenges and Learning

* I had the change to test my idea and I did open up my horizon more on my personal project. However, I believe using AI is not helping people to interact their environments more. Where it also creates a dilemma of attaching people more from reality.
* We didn't have time and resources (portable projection) to test the idea in intended usage areas. This could have give us more feedbacks. We only tested within class; however, I believe it doesn't reflect truly.
* Metronom device could have been improved more. It could be more interactive, welcoming the users and explaining how and why to use. We wanted to implement also a way other then an APP to capture their environment and connect with the TouchDesigner.
* We could have tried other technologies than TouchDesigner or AI Technolog which was problematic.
* One of our main problems was the representation and alteration of human bodies with AI. Eventhough prompted otherwise, AI altered human bodies in a way that is conflicting with our intention.


This was really a hands on course where we had to change to prototype, where I had a lot of fun! I'd like to than my teammate Armin for collaboration, and to our instructors Santi, Julia, Mikel.
